{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45d228d9-1d5e-4621-a8c9-30605c494b25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+-----+---+\n|dno|eid|  ename|  sal|sex|\n+---+---+-------+-----+---+\n| 11|101| Miller|10000|  m|\n| 12|102|  Blake|20000|  m|\n| 11|103|   Sony|30000|  f|\n| 12|104|  Sonia|40000|  f|\n| 13|105|  James|50000|  m|\n| 14|106|  pavan|60000|  m|\n| 15|107|praveen|70000|  m|\n| 16|108|   John|80000|  m|\n+---+---+-------+-----+---+\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('json').load('/Volumes/dev/haridb/myvolume/emps2.json')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1867bcf5-9f97-4432-bfbb-2e6f0392bcd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---+\n|   city|   dname|dno|\n+-------+--------+---+\n|    Hyd|    Mrkt| 11|\n|   Pune|     Fin| 12|\n| Mumbai|      HR| 13|\n|    Hyd|   sales| 17|\n|Chennai|Accounts| 18|\n|    Hyd|   Admin| 19|\n+-------+--------+---+\n\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.read.format('json').load('/Volumes/dev/haridb/myvolume/dept.json')\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb601420-de22-4939-8e29-b37bb8e5ee38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+-----+---+------+-----+---+\n|dno|eid| ename|  sal|sex|  city|dname|dno|\n+---+---+------+-----+---+------+-----+---+\n| 11|101|Miller|10000|  m|   Hyd| Mrkt| 11|\n| 12|102| Blake|20000|  m|  Pune|  Fin| 12|\n| 11|103|  Sony|30000|  f|   Hyd| Mrkt| 11|\n| 12|104| Sonia|40000|  f|  Pune|  Fin| 12|\n| 13|105| James|50000|  m|Mumbai|   HR| 13|\n+---+---+------+-----+---+------+-----+---+\n\n"
     ]
    }
   ],
   "source": [
    "df.join(df1, df.dno == df1.dno, \"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7195b436-ad86-40d6-9375-09282a9f11b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+-----+---+------+-----+\n|dno|eid| ename|  sal|sex|  city|dname|\n+---+---+------+-----+---+------+-----+\n| 11|101|Miller|10000|  m|   Hyd| Mrkt|\n| 12|102| Blake|20000|  m|  Pune|  Fin|\n| 11|103|  Sony|30000|  f|   Hyd| Mrkt|\n| 12|104| Sonia|40000|  f|  Pune|  Fin|\n| 13|105| James|50000|  m|Mumbai|   HR|\n+---+---+------+-----+---+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df.join(df1, \"dno\", \"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a16f4833-b62e-4d24-afab-f9a869ba1dfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEFT_OUTER_JOIN : \n+---+---+-------+-----+---+------+-----+\n|dno|eid|  ename|  sal|sex|  city|dname|\n+---+---+-------+-----+---+------+-----+\n| 11|101| Miller|10000|  m|   Hyd| Mrkt|\n| 12|102|  Blake|20000|  m|  Pune|  Fin|\n| 11|103|   Sony|30000|  f|   Hyd| Mrkt|\n| 12|104|  Sonia|40000|  f|  Pune|  Fin|\n| 13|105|  James|50000|  m|Mumbai|   HR|\n| 14|106|  pavan|60000|  m|  NULL| NULL|\n| 15|107|praveen|70000|  m|  NULL| NULL|\n| 16|108|   John|80000|  m|  NULL| NULL|\n+---+---+-------+-----+---+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"LEFT_OUTER_JOIN : \")\n",
    "df.join(df1, \"dno\", \"left_outer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dda65dd-211c-42f4-a10d-abb15aee2425",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+-----+----+-------+--------+\n|dno| eid| ename|  sal| sex|   city|   dname|\n+---+----+------+-----+----+-------+--------+\n| 11| 103|  Sony|30000|   f|    Hyd|    Mrkt|\n| 11| 101|Miller|10000|   m|    Hyd|    Mrkt|\n| 12| 104| Sonia|40000|   f|   Pune|     Fin|\n| 12| 102| Blake|20000|   m|   Pune|     Fin|\n| 13| 105| James|50000|   m| Mumbai|      HR|\n| 17|NULL|  NULL| NULL|NULL|    Hyd|   sales|\n| 18|NULL|  NULL| NULL|NULL|Chennai|Accounts|\n| 19|NULL|  NULL| NULL|NULL|    Hyd|   Admin|\n+---+----+------+-----+----+-------+--------+\n\nright_outer_join None\n"
     ]
    }
   ],
   "source": [
    "print(\"right_outer_join\", df.join(df1,\"dno\",\"right_outer\").show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "327bc75d-f7d4-4e35-8eb0-239500f52504",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+-----+----+-------+--------+\n|dno| eid|  ename|  sal| sex|   city|   dname|\n+---+----+-------+-----+----+-------+--------+\n| 11| 101| Miller|10000|   m|    Hyd|    Mrkt|\n| 11| 103|   Sony|30000|   f|    Hyd|    Mrkt|\n| 12| 102|  Blake|20000|   m|   Pune|     Fin|\n| 12| 104|  Sonia|40000|   f|   Pune|     Fin|\n| 13| 105|  James|50000|   m| Mumbai|      HR|\n| 14| 106|  pavan|60000|   m|   NULL|    NULL|\n| 15| 107|praveen|70000|   m|   NULL|    NULL|\n| 16| 108|   John|80000|   m|   NULL|    NULL|\n| 17|NULL|   NULL| NULL|NULL|    Hyd|   sales|\n| 18|NULL|   NULL| NULL|NULL|Chennai|Accounts|\n| 19|NULL|   NULL| NULL|NULL|    Hyd|   Admin|\n+---+----+-------+-----+----+-------+--------+\n\nfull_OUTER_JOIN None\n"
     ]
    }
   ],
   "source": [
    "print(\"full_OUTER_JOIN\",df.join(df1,\"dno\",\"full_outer\").show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce74b865-2b26-485f-aa30-31f0440749da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+-----+----+-------+--------+\n|dno| eid|  ename|  sal| sex|   city|   dname|\n+---+----+-------+-----+----+-------+--------+\n| 11| 101| Miller|10000|   m|    Hyd|    Mrkt|\n| 11| 103|   Sony|30000|   f|    Hyd|    Mrkt|\n| 12| 102|  Blake|20000|   m|   Pune|     Fin|\n| 12| 104|  Sonia|40000|   f|   Pune|     Fin|\n| 13| 105|  James|50000|   m| Mumbai|      HR|\n| 14| 106|  pavan|60000|   m|   NULL|    NULL|\n| 15| 107|praveen|70000|   m|   NULL|    NULL|\n| 16| 108|   John|80000|   m|   NULL|    NULL|\n| 17|NULL|   NULL| NULL|NULL|    Hyd|   sales|\n| 18|NULL|   NULL| NULL|NULL|Chennai|Accounts|\n| 19|NULL|   NULL| NULL|NULL|    Hyd|   Admin|\n+---+----+-------+-----+----+-------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "foj = df.join(df1,\"dno\",\"full_outer\")\n",
    "foj.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e976a48c-b4ca-4eb5-8d96-c6811a6fa6b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+-----+---+------+-----+\n|dno|eid| ename|  sal|sex|  city|dname|\n+---+---+------+-----+---+------+-----+\n| 11|101|Miller|10000|  m|   Hyd| Mrkt|\n| 11|103|  Sony|30000|  f|   Hyd| Mrkt|\n| 12|102| Blake|20000|  m|  Pune|  Fin|\n| 12|104| Sonia|40000|  f|  Pune|  Fin|\n| 13|105| James|50000|  m|Mumbai|   HR|\n+---+---+------+-----+---+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "foj.dropna().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfcc144b-7d9b-4d55-b421-e9d88d8c5d47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+-----+----+-------+--------+\n|dno| eid|  ename|  sal| sex|   city|   dname|\n+---+----+-------+-----+----+-------+--------+\n| 11| 101| Miller|10000|   m|    Hyd|    Mrkt|\n| 11| 103|   Sony|30000|   f|    Hyd|    Mrkt|\n| 12| 102|  Blake|20000|   m|   Pune|     Fin|\n| 12| 104|  Sonia|40000|   f|   Pune|     Fin|\n| 13| 105|  James|50000|   m| Mumbai|      HR|\n| 14| 106|  pavan|60000|   m|   NULL|    NULL|\n| 15| 107|praveen|70000|   m|   NULL|    NULL|\n| 16| 108|   John|80000|   m|   NULL|    NULL|\n| 17|NULL|   NULL| NULL|NULL|    Hyd|   sales|\n| 18|NULL|   NULL| NULL|NULL|Chennai|Accounts|\n| 19|NULL|   NULL| NULL|NULL|    Hyd|   Admin|\n+---+----+-------+-----+----+-------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "foj.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cee70e1d-e309-40b5-b6d9-b750d75d7d1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+-----+----+-------+--------+\n|dno|eid|  ename|  sal| sex|   city|   dname|\n+---+---+-------+-----+----+-------+--------+\n| 11|101| Miller|10000|   m|    Hyd|    Mrkt|\n| 11|103|   Sony|30000|   f|    Hyd|    Mrkt|\n| 12|102|  Blake|20000|   m|   Pune|     Fin|\n| 12|104|  Sonia|40000|   f|   Pune|     Fin|\n| 13|105|  James|50000|   m| Mumbai|      HR|\n| 14|106|  pavan|60000|   m|   NULL|    NULL|\n| 15|107|praveen|70000|   m|   NULL|    NULL|\n| 16|108|   John|80000|   m|   NULL|    NULL|\n| 17|  0|   NULL|    0|NULL|    Hyd|   sales|\n| 18|  0|   NULL|    0|NULL|Chennai|Accounts|\n| 19|  0|   NULL|    0|NULL|    Hyd|   Admin|\n+---+---+-------+-----+----+-------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "foj.na.fill(0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4cd892e-9239-4e4b-ba75-5e24ca35c3ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+-----+-------+-------+--------+\n|dno|eid|  ename|  sal|    sex|   city|   dname|\n+---+---+-------+-----+-------+-------+--------+\n| 11|101| Miller|10000|      m|    Hyd|    Mrkt|\n| 11|103|   Sony|30000|      f|    Hyd|    Mrkt|\n| 12|102|  Blake|20000|      m|   Pune|     Fin|\n| 12|104|  Sonia|40000|      f|   Pune|     Fin|\n| 13|105|  James|50000|      m| Mumbai|      HR|\n| 14|106|  pavan|60000|      m|Unknown| Unknown|\n| 15|107|praveen|70000|      m|Unknown| Unknown|\n| 16|108|   John|80000|      m|Unknown| Unknown|\n| 17|  0|Unknown|    0|Unknown|    Hyd|   sales|\n| 18|  0|Unknown|    0|Unknown|Chennai|Accounts|\n| 19|  0|Unknown|    0|Unknown|    Hyd|   Admin|\n+---+---+-------+-----+-------+-------+--------+\n\n+---+----+-------+-----+------+-------+--------+\n|dno| eid|  ename|  sal|   sex|   city|   dname|\n+---+----+-------+-----+------+-------+--------+\n| 11| 101| Miller|10000|  Male|    Hyd|    Mrkt|\n| 11| 103|   Sony|30000|female|    Hyd|    Mrkt|\n| 12| 102|  Blake|20000|  Male|   Pune|     Fin|\n| 12| 104|  Sonia|40000|female|   Pune|     Fin|\n| 13| 105|  James|50000|  Male| Mumbai|      HR|\n| 14| 106|  pavan|60000|  Male|   NULL|    NULL|\n| 15| 107|praveen|70000|  Male|   NULL|    NULL|\n| 16| 108|   John|80000|  Male|   NULL|    NULL|\n| 17|NULL|   NULL| NULL|  NULL|    Hyd|   sales|\n| 18|NULL|   NULL| NULL|  NULL|Chennai|Accounts|\n| 19|NULL|   NULL| NULL|  NULL|    Hyd|   Admin|\n+---+----+-------+-----+------+-------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "foj.na.fill({\n",
    "    \"ename\" : \"Unknown\",\n",
    "    \"sex\" : \"Unknown\",\n",
    "    \"city\" : \"Unknown\",\n",
    "    \"dname\" : \"Unknown\",\n",
    "    \"eid\" : 0,\n",
    "    \"sal\" : 0\n",
    "}) .show()\n",
    "foj.replace({\n",
    "    'm' : 'Male',\n",
    "    'f' : 'female'\n",
    "    }) .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff1415f6-c383-43ad-9aa6-d2a466f609ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n|  _1| _2|\n+----+---+\n|Hari|101|\n|Ravi|102|\n| Jai|103|\n+----+---+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(\"Hari\",101) ,(\"Ravi\",102),(\"Jai\",103)]\n",
    "df2  = spark.createDataFrame(data)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78c8ee88-8344-4d72-a67e-e0ffc98d56ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n|Name| Id|\n+----+---+\n|Hari|101|\n|Ravi|102|\n| Jai|103|\n+----+---+\n\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.createDataFrame(data, [\"Name\",'Id'])\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "316d0664-fadb-4d1e-a139-1c08ddeaab1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Name: string (nullable = true)\n |-- Id: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1917ec0-d2f3-42b5-acc0-09aea9e3b492",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Dataframe is a collection of Row objects,\n",
    "EAch row object repreents a record\n",
    "\n",
    "DataFrames can be created in 2 ways using\n",
    "\n",
    "1)spark session->ex:df=spark.createDataFrame(RDD) #here spark is spark session object\n",
    "2)sqlContext---->ex:df=sqlContext.createDataFrame(RDD)\n",
    "\n",
    "\n",
    "Creating Dataframes :\n",
    "\n",
    "1)from local objects(python objects)\n",
    "2)from rdds(resilient distributed datasets)\n",
    "3)from the results of sql queries we get a DataFrame\n",
    "4)from External Datasources like CSV,json et"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9de19909-7d3e-4272-8f11-bc0f10345404",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Four different ways to provide schema\n",
    "1. while creating df and providing Schema\n",
    "2. using python Libarary\n",
    "3. using row object\n",
    "4. using StruckType and StruckField (using PySpark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad1a6293-2488-4840-96c9-f26451048a23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n|Name: string|Id : Integer|\n+------------+------------+\n|        Hari|         101|\n|        Ravi|         102|\n|         Jai|         103|\n+------------+------------+\n\nroot\n |-- Name: string: string (nullable = true)\n |-- Id : Integer: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# while creating df and providing Schema\n",
    "\n",
    "df3 = [(\"Hari\",101) ,(\"Ravi\",102),(\"Jai\",103)]\n",
    "df3 = spark.createDataFrame(df3,[\"Name: string\",\"Id : Integer\"])\n",
    "df3.show()\n",
    "df3.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21ec5478-65ab-48a6-9e90-714b94d50955",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n|Name| Id|\n+----+---+\n|Hari|101|\n|Ravi|102|\n| Jai|103|\n+----+---+\n\nroot\n |-- Name: string (nullable = true)\n |-- Id: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Using Python Library pandas\n",
    "df4 = spark.createDataFrame(df3.toPandas(), schema=('Name string, Id int'))\n",
    "df4.show()\n",
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab010fd7-edad-4865-be66-befb3215ada5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n|      Name|      Id|\n+----------+--------+\n|skdfhskjdf|    1182|\n|   asd;fkj|     112|\n|  asdf;lkj|76537256|\n+----------+--------+\n\nroot\n |-- Name: string (nullable = true)\n |-- Id: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# using row object ------> RDD(SparkObject) ---> SparkObject(DF)\n",
    "\n",
    "df5 = [('skdfhskjdf',1182), ('asd;fkj',112), ('asdf;lkj',76537256)]\n",
    "# how to convert a python object to Spark Object??\n",
    "rdd = spark.sparkContext.parallelize(df5)  #SC is SparkContext\n",
    "# df = rdd + schema\n",
    "df5 = spark.createDataFrame(rdd, schema=('Name: string, Id: int'))\n",
    "df5.show()\n",
    "df5.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a742994-8b1d-4c4c-90aa-73d97fcff7c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n|    name| age|\n+--------+----+\n|     Jai|   9|\n|Agasthya|  10|\n| Vincent|NULL|\n|    NULL|   5|\n+--------+----+\n\nroot\n |-- name: string (nullable = true)\n |-- age: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Providing custom schema using StructType\n",
    "\n",
    "# using StruckType and StruckField (using PySpark)\n",
    "\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "X = [('Jai',9),('Agasthya',10),('Vincent', None), (None, 5)]\n",
    "schema = StructType(\n",
    "    [StructField(\"name\",StringType(),True),\n",
    "     StructField(\"age\",IntegerType(),True)])\n",
    "df = spark.createDataFrame(X,schema)\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DataFrames_API",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}